{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n===============================================================================\n01. pyUSID in 10 minutes\n===============================================================================\n\n**Suhas Somnath**\n\n4/10/2020\n\n**This document serves as a quick primer to the essential components of\npyUSID**\n\nRecommended pre-requisite reading\n---------------------------------\n* `Universal Spectroscopic and Imaging Data (USID) model\n  </../../../USID/usid_model.html>`_\n* `Crash course on HDF5 and h5py <./plot_h5py.html>`_\n\n**This document is under construction**\n\n* first make some dummy data using Numpy or Dask - let it have 3-4 dimensions. Use examples in the [hdf_utils cookbook](https://pycroscopy.github.io/pyUSID/auto_examples/intermediate/plot_hdf_utils_write.html)\n* ``hdf_utils.reshape_from_n_dims()`` -> convert main 4D data to 2D\n* Construct ``write_utils.Dimension`` objects. Again take inspiration from above example\n* Use ``plot_utils.plot_map()`` and one other function here just to point out that such handy functions exist\n* Use ``ArrayTranslator`` to write to file\n* Show how one would open an existing HDF5 file using ``h5py.File``\n* ``hdf_utils.print_tree(h5_file)`` to show all existing contents. Maybe set to ``main_only`` to simplify\n* Demonstrate creation of USIDataset via: ``USIDataset(main dataset here)``\n* ``print(usi_dataset_object)``\n* ``usi_dataset_object.get_n_dim_form()``\n* ``usi_dataset_object.slice()`` -> Maybe use ``plot_utils`` here to show results.\n* ``usi_dataset_object.visualize()`` -> slice to 2D for simpler / static visualization but point out that interactive widgets are available for > 2D visualization\n* ``usi_dataset_object.get_unit_values()``\n* Make an indexed group for results using ``hdf_utils.create_indexed_group``. Point out that ``hdf_utils.create_results_group()`` does something similar\n* ``hdf_utils.write_simple_attrs()`` to group.\n* Show ``hdf_utils.get_attributes()`` and ``hdf_utils.get_attr()`` from this group\n* Illustrate how one might create results based on processing performed on the original data\nusing ``hdf_utils.write_main_data``\n* ``hdf_utils.check_if_main(results_dataset)`` to make sure that it is main. No surprises here\n* ``hdf_utils.get_all_main(h5_file)`` in the end to show that you will get more than 1 dataset\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}